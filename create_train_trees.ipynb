{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "create_train_trees.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRGsXgNtZ6JE",
        "colab_type": "text"
      },
      "source": [
        "##Connect to cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xnAj6GVY4i_",
        "colab_type": "code",
        "outputId": "69e3a2c6-df42-4ff4-bcab-efac3ced5304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR880mLsiBnS",
        "colab_type": "text"
      },
      "source": [
        "##Trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muRONHGqiARL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "\n",
        "GOAL = \"demand\"\n",
        "\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, data, choices=None, depth=0):\n",
        "        self.data = data\n",
        "        self.choices = choices\n",
        "        self.children = []\n",
        "        self.depth = depth\n",
        "\n",
        "    def __del__(self):\n",
        "        for child in self.children:\n",
        "            del child\n",
        "        del self.children\n",
        "\n",
        "    def add_children(self, children):\n",
        "        self.children = children\n",
        "\n",
        "\n",
        "class Tree:\n",
        "    def __init__(self, records_df, limit=0, attributes=None, goal=GOAL, name=\"\"):\n",
        "        \"\"\"creates the tree based on a dictionary of attributes and options\"\"\"\n",
        "        self.limit = limit\n",
        "        self.goal = goal\n",
        "        self.name = name\n",
        "        if records_df is not None:\n",
        "            self.rows = len(records_df)\n",
        "            self.root = self.create_tree(records_df, attributes)\n",
        "        else:\n",
        "            self.root = Node(None)\n",
        "\n",
        "    def __del__(self):\n",
        "        del self.root\n",
        "\n",
        "    def create_tree(self, records_df, attributes=None):\n",
        "        \"\"\"creates the tree and returns the root\"\"\"\n",
        "        if not attributes:\n",
        "            attributes = list(records_df.columns)\n",
        "            attributes.remove(self.goal)\n",
        "        return self.recursive_build(records_df, attributes, [], 0)\n",
        "\n",
        "    def recursive_build(self, records_df, attributes, path, depth):\n",
        "        \"\"\"Recursive helper to build the tree\"\"\"\n",
        "        if self.limit and self.limit <= depth:\n",
        "            attribute = None\n",
        "        else:\n",
        "            attribute = self.get_next_attribute(attributes, records_df)\n",
        "            while attribute and len(records_df[attribute].value_counts()) == 1:\n",
        "                attributes.remove(attribute)\n",
        "                attribute = self.get_next_attribute(attributes, records_df)\n",
        "        if not attribute:\n",
        "            attribute = self.goal\n",
        "        if attribute != self.goal:\n",
        "            attributes.remove(attribute)\n",
        "            if not path:\n",
        "                node = Node(attribute, depth=depth)\n",
        "            else:\n",
        "                node = Node(attribute, path, depth)\n",
        "            children = []\n",
        "            for val in records_df[attribute].unique():\n",
        "                new_data = records_df[records_df[attribute] == val]\n",
        "                new_path = copy.deepcopy(path + [(attribute, val)])\n",
        "                records_df = records_df[records_df[attribute] != val]\n",
        "                remaining = copy.deepcopy(attributes)\n",
        "                children.append(self.recursive_build(new_data, remaining,\n",
        "                                                     new_path, depth + 1))\n",
        "            node.add_children(children)\n",
        "        else:\n",
        "            node = Node(self.decide_leaf(records_df), path, depth=depth)\n",
        "        return node\n",
        "\n",
        "    def get_next_attribute(self, attribute_list, records_df):\n",
        "        \"\"\"returns the next attribute\"\"\"\n",
        "        if attribute_list:\n",
        "            return attribute_list[0]\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def decide_leaf(self, records_df):\n",
        "        \"\"\"Decide the value of the leaf based on the records\"\"\"\n",
        "        if records_df.empty:\n",
        "            return None\n",
        "        return records_df[self.goal].value_counts().argmax()\n",
        "\n",
        "    def pruning(self, records_df, threshold):\n",
        "        \"\"\"Prunes the tree based on a threshold\"\"\"\n",
        "        nodes_to_check = [self.root]\n",
        "        while nodes_to_check:\n",
        "            node = nodes_to_check.pop()\n",
        "            children_remove = []\n",
        "            children_append = []\n",
        "            for child in node.children:\n",
        "                path = child.choices\n",
        "                depth = child.depth\n",
        "                relevant = copy.deepcopy(records_df)\n",
        "                for attribute, value in path:\n",
        "                    relevant = relevant[relevant[attribute] == value]\n",
        "                if len(relevant) / self.rows <= threshold:\n",
        "                    children_remove.append(child)\n",
        "                    children_append.append(Node(self.decide_leaf(relevant),\n",
        "                                              path, depth=depth))\n",
        "                else:\n",
        "                    nodes_to_check.append(child)\n",
        "            for child in children_remove:\n",
        "                node.children.remove(child)\n",
        "            for child in children_append:\n",
        "                node.children.append(child)\n",
        "\n",
        "    def get_val(self, df_row):\n",
        "        \"\"\"Gets the relevant node based on the row\"\"\"\n",
        "        node = self.root\n",
        "        while node:\n",
        "            prev_node = node\n",
        "            if not len(node.children):\n",
        "                return node.data\n",
        "            if node.data not in df_row.keys():\n",
        "                return None\n",
        "            children = prev_node.children\n",
        "            for child in children:\n",
        "                if child.choices[-1][1] == df_row[prev_node.data]:\n",
        "                    node = child\n",
        "                    break\n",
        "                else:\n",
        "                    node = None\n",
        "        return None\n",
        "\n",
        "    def save_tree(self, output_path):\n",
        "        \"\"\"Saves the tree\"\"\"\n",
        "        with open(output_path, 'wb') as file:\n",
        "            pickle.dump(self, file)\n",
        "\n",
        "    def load_tree(self, path):\n",
        "        \"\"\"Saves the tree\"\"\"\n",
        "        with open(path, 'rb') as file:\n",
        "            node = pickle.load(file)\n",
        "        self.root = node.root\n",
        "        self.name = path.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "\n",
        "class EntropyTree(Tree):\n",
        "    def get_next_attribute(self, attribute_list, records_df):\n",
        "        \"\"\"returns the attribute with the minimum entropy\"\"\"\n",
        "        entropy = calc_entropy(attribute_list, records_df)\n",
        "        entropy = {k: v for k, v in entropy.items() if v}\n",
        "        if len(entropy):\n",
        "            return min(entropy, key=entropy.get)\n",
        "        return None\n",
        "\n",
        "\n",
        "class InformationGainTree(Tree):\n",
        "    def get_next_attribute(self, attribute_list, records_df):\n",
        "        \"\"\"Returns the attribute with the highest information gain\"\"\"\n",
        "        info_gain = information_gain(attribute_list, records_df)\n",
        "        if len(info_gain):\n",
        "            return max(info_gain, key=info_gain.get)\n",
        "        return None\n",
        "\n",
        "\n",
        "class InformationRatioTree(Tree):\n",
        "    def get_next_attribute(self, attribute_list, records_df):\n",
        "        \"\"\"Returns the attribute with the highest information gain ratio\"\"\"\n",
        "        info_gain = information_gain(attribute_list, records_df)\n",
        "        info_gain_ratio = dict()\n",
        "        for attribute in attribute_list:\n",
        "            p = records_df[attribute].value_counts() / len(records_df)\n",
        "            int_value = -np.sum(p * np.log2(p))\n",
        "            info_gain_ratio[attribute] = info_gain[attribute] / int_value\n",
        "        if len(info_gain_ratio):\n",
        "            return max(info_gain_ratio, key=info_gain_ratio.get)\n",
        "        return None\n",
        "\n",
        "\n",
        "def calc_entropy(attribute_list, records_df):\n",
        "    \"\"\"Returns the entropy dictionary\"\"\"\n",
        "    entropy = dict()\n",
        "    for attribute in attribute_list:\n",
        "        p = records_df[attribute].value_counts() / len(records_df)\n",
        "        entropy[attribute] = -np.sum(p * np.log2(p))\n",
        "    return entropy\n",
        "\n",
        "\n",
        "def information_gain(attribute_list, records_df, goal=GOAL):\n",
        "    \"\"\"Returns a dictionary of the information gain\"\"\"\n",
        "    goal_entropy = calc_entropy([goal], records_df)[goal]\n",
        "    info_gain = dict()\n",
        "    for attribute in attribute_list:\n",
        "        remaining_entropy = 0\n",
        "        for val in records_df[attribute].unique():\n",
        "            relevant = records_df[records_df[attribute] == val]\n",
        "            p = relevant[goal].value_counts() / len(relevant)\n",
        "            remaining_entropy += -(np.sum(p * np.log2(p) * len(relevant)) / len(records_df))\n",
        "        info_gain[attribute] = goal_entropy - remaining_entropy\n",
        "    return info_gain\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q3irnrraQXX",
        "colab_type": "text"
      },
      "source": [
        "##Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPXFTT18fDwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "from multiprocessing import Pool"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsxzgQDFaGtQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH_TO_FOLDER = \"/content/gdrive/My Drive/AI_project/\"\n",
        "INPUT_PATH = \"Data/training_data_1.csv\"\n",
        "TEST_PATH = \"Data/test_data_1.csv\"\n",
        "TRAINING_SET = \"1\"\n",
        "\n",
        "GOAL = \"demand\"\n",
        "TRAIN_LEVEL = 0.5\n",
        "POOL_SIZE = 4\n",
        "TREE = \"Tree\"\n",
        "ENTROPY = \"EntropyTree\"\n",
        "INFORMATION_GAIN = \"InformationGainTree\"\n",
        "INFORMATION_RATIO = \"InformationRatioTree\"\n",
        "\n",
        "BASIC_ATTRIBUTES = [\"L1\", \"L2\", \"time\"]\n",
        "IGNORE_LIST = BASIC_ATTRIBUTES + [\"Unnamed: 0\", \"Unnamed: 0.1\", \"cluster_id\",\n",
        "                                  \"thunderstorm\", \"foggy\", \"humidity\", \"demand\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B9HuLlOaWs_",
        "colab_type": "text"
      },
      "source": [
        "##Function defenitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csxjot8taXFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tree_creation(type, records_df, limit=0, attributes=None, goal=GOAL, name=\"\"):\n",
        "    \"\"\"This function creates the trees\"\"\"\n",
        "    if type == TREE:\n",
        "        return Tree(records_df, limit, attributes, goal, name)\n",
        "    elif type == ENTROPY:\n",
        "        return EntropyTree(records_df, limit, attributes, goal, name)\n",
        "    elif type == INFORMATION_GAIN:\n",
        "        return InformationGainTree(records_df, limit, attributes, goal, name)\n",
        "    elif type == INFORMATION_RATIO:\n",
        "        return InformationRatioTree(records_df, limit, attributes, goal, name)\n",
        "    else:\n",
        "        return\n",
        "\n",
        "\n",
        "def create_attributes_list(data):\n",
        "    \"\"\"Creates a list of attributes in order to build th trees\"\"\"\n",
        "    attributes_list = []\n",
        "    for column in data.columns:\n",
        "        if column not in IGNORE_LIST:\n",
        "            attributes_list.append(BASIC_ATTRIBUTES + [column])\n",
        "    return attributes_list\n",
        "\n",
        "\n",
        "def get_type(tree):\n",
        "    \"\"\"Gets the type of the tree\"\"\"\n",
        "    return str(type(tree)).split('.')[1].split('\\'')[0]\n",
        "\n",
        "\n",
        "def create_trees(training_data, goal):\n",
        "    p = Pool(POOL_SIZE)\n",
        "    all_trees = []\n",
        "    # every tree we want to create has to come in the format of\n",
        "    # (type, df, limit, attributes, goal)\n",
        "    attr_list = create_attributes_list(training_data)\n",
        "    for lst in attr_list:\n",
        "        print(lst[-1])\n",
        "        trees = [(TREE, training_data, 0, lst, goal, TREE + \"_\" + lst[-1] +\n",
        "                  \"_\" + TRAINING_SET)]\n",
        "        trees.append((ENTROPY, training_data, 0, lst, goal,\n",
        "                      ENTROPY + \"_\" + lst[-1] + \"_\" + TRAINING_SET))\n",
        "        trees.append((INFORMATION_GAIN, training_data, 0, lst, goal,\n",
        "                      INFORMATION_GAIN + \"_\" + lst[-1] + \"_\" + TRAINING_SET))\n",
        "        trees.append((INFORMATION_RATIO, training_data, 0, lst, goal,\n",
        "                      INFORMATION_RATIO + \"_\" + lst[-1] + \"_\" + TRAINING_SET))\n",
        "        res = p.starmap(tree_creation, trees)\n",
        "        for t in res:\n",
        "            t.save_tree(PATH_TO_FOLDER + \"Trees/\" + t.name + \".txt\")\n",
        "            all_trees.append(t)\n",
        "    p.close()\n",
        "    p.join()\n",
        "    return all_trees\n",
        "\n",
        "\n",
        "def create_file(test_data, all_trees, goal):\n",
        "    \"\"\"This function generates a file with the results of each tree and the\n",
        "    actual result per line in the test data\"\"\"\n",
        "    columns = [t.name for t in all_trees]\n",
        "    columns.append(goal)\n",
        "    output = pd.DataFrame(columns=columns)\n",
        "    counter = 0\n",
        "#     for i in range(len(test_data)):\n",
        "#         print(str(i) + \" out of \" + str(len(test_data)), len(output))\n",
        "    while not test_data.empty:\n",
        "        test_data, row = test_data.iloc[1:], test_data.head(1)\n",
        "        print(len(test_data), len(output))\n",
        "        row_dict = dict()\n",
        "#         row = test_data.iloc[i, :]\n",
        "        for t in all_trees:\n",
        "            row_dict[t.name] = t.get_val(row)\n",
        "        row_dict[goal] = row[goal]\n",
        "        output = output.append(pd.DataFrame.from_dict([row_dict]))\n",
        "        if len(output) >= 10000:\n",
        "            output.to_csv(PATH_TO_FOLDER + \"Data/testing_by_tree\" + TRAINING_SET + \"_part_\" + str(counter) + \".csv\")\n",
        "            counter += 1\n",
        "            del output\n",
        "            output = pd.DataFrame(columns=columns)\n",
        "        del row\n",
        "    if not output.empty:\n",
        "        output.to_csv(PATH_TO_FOLDER + \"Data/testing_by_tree\" + TRAINING_SET + \"_part_\" + str(counter) + \".csv\")\n",
        "\n",
        "\n",
        "def export_training_and_test(training_data, test_data):\n",
        "    \"\"\"This functino saves the training data and the testing data\"\"\"\n",
        "    training_data.to_csv(\"training_data.csv\")\n",
        "    test_data.to_csv(\"test_data.csv\")\n",
        "    \n",
        "def load_data(path):\n",
        "    \"\"\"\"\"\"\n",
        "    return pd.read_csv(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUJxExWnKpVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def additional_trees(training_data, goal):\n",
        "    \"\"\"\"\"\"\n",
        "    p = Pool(POOL_SIZE)\n",
        "    # every tree we want to create has to come in the format of\n",
        "    # (type, df, limit, attributes, goal)\n",
        "    all_trees = []\n",
        "    new_basic = BASIC_ATTRIBUTES + [\"weekday\"]\n",
        "    attr_list = [new_basic + [\"month\"]]\n",
        "    attr_list.append(new_basic + [\"clear_sky\"])\n",
        "    attr_list.append(new_basic + [\"extreme_weather\"])\n",
        "    attr_list.append(new_basic + [\"clear_sky\", \"extreme_weather\"])\n",
        "    for lst in attr_list:\n",
        "        filename = \"_\".join(list(set(lst) - set(BASIC_ATTRIBUTES)))\n",
        "        print(filename)\n",
        "        trees = [(TREE, training_data, 0, lst, goal,\n",
        "                  TREE + \"_\" + filename + \"_\" + TRAINING_SET)]\n",
        "        trees.append((ENTROPY, training_data, 0, lst, goal,\n",
        "                      ENTROPY + \"_\" + filename + \"_\" + TRAINING_SET))\n",
        "        trees.append((INFORMATION_GAIN, training_data, 0, lst, goal,\n",
        "                      INFORMATION_GAIN + \"_\" + filename + \"_\" + TRAINING_SET))\n",
        "        trees.append((INFORMATION_RATIO, training_data, 0, lst, goal,\n",
        "                      INFORMATION_RATIO + \"_\" + filename + \"_\" + TRAINING_SET))\n",
        "        res = p.starmap(tree_creation, trees)\n",
        "        for t in res:\n",
        "            t.save_tree(PATH_TO_FOLDER + \"Trees/\" + t.name + \".txt\")\n",
        "            all_trees.append(t)\n",
        "    p.close()\n",
        "    p.join()\n",
        "    return all_trees\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RL-gClZ7Eyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "def get_tree_files():\n",
        "    onlyfiles = [f for f in listdir(PATH_TO_FOLDER + \"Trees\") if\n",
        "             isfile(join(PATH_TO_FOLDER + \"Trees\", f)) and TRAINING_SET in f]\n",
        "    return onlyfiles\n",
        "\n",
        "\n",
        "def load_all_trees():\n",
        "    files = get_tree_files()\n",
        "    trees = []\n",
        "    for file in files:\n",
        "        new_tree = Tree(None)\n",
        "        new_tree.load_tree(join(PATH_TO_FOLDER + \"Trees\", file))\n",
        "        trees.append(new_tree)\n",
        "    return trees"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCH1bYYHagvA",
        "colab_type": "text"
      },
      "source": [
        "##Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwa5RVwipeN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = pd.read_csv(PATH_TO_FOLDER + TEST_PATH)\n",
        "create_file(test_data, [], GOAL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBtorAPyaSf3",
        "colab_type": "code",
        "outputId": "e63dbfc7-83e3-4f22-9684-e6800927bd5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "    training_data = pd.read_csv(PATH_TO_FOLDER + INPUT_PATH)\n",
        "    # create trees based on training data\n",
        "#     all_trees = create_trees(training_data, GOAL)\n",
        "    print(\"finish normal trees\")\n",
        "#     all_trees.extend(additional_trees(training_data, GOAL))\n",
        "    # export_trees(all_trees)\n",
        "    \n",
        "    print(\"finished\")\n",
        "    del training_data\n",
        "    all_trees = load_all_trees()\n",
        "    test_data = pd.read_csv(PATH_TO_FOLDER + TEST_PATH)\n",
        "#     create file\n",
        "    create_file(test_data, all_trees, GOAL)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finish normal trees\n",
            "finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-84e01a879365>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"finished\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mall_trees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_all_trees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_TO_FOLDER\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTEST_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#     create file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-5fa5d544452e>\u001b[0m in \u001b[0;36mload_all_trees\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mnew_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mnew_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_TO_FOLDER\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"Trees\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-1d175b24e101>\u001b[0m in \u001b[0;36mload_tree\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;34m\"\"\"Saves the tree\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tree'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}