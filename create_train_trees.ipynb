{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "create_train_trees.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRGsXgNtZ6JE",
        "colab_type": "text"
      },
      "source": [
        "##Connect to cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xnAj6GVY4i_",
        "colab_type": "code",
        "outputId": "a2214c73-c2a4-4a43-cee1-62d177d5ffd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR880mLsiBnS",
        "colab_type": "text"
      },
      "source": [
        "##Trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muRONHGqiARL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "\n",
        "GOAL = \"demand\"\n",
        "\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, data, choices=None, depth=0):\n",
        "        self.data = data\n",
        "        self.choices = choices\n",
        "        self.children = []\n",
        "        self.depth = depth\n",
        "\n",
        "    def __del__(self):\n",
        "        for child in self.children:\n",
        "            del child\n",
        "        del self.children\n",
        "\n",
        "    def add_children(self, children):\n",
        "        self.children = children\n",
        "\n",
        "\n",
        "class Tree:\n",
        "    def __init__(self, records_df, limit=0, attributes=None, goal=GOAL):\n",
        "        \"\"\"creates the tree based on a dictionary of attributes and options\"\"\"\n",
        "        self.limit = limit\n",
        "        self.goal = goal\n",
        "        if records_df is not None:\n",
        "            self.rows = len(records_df)\n",
        "            self.root = self.create_tree(records_df, attributes)\n",
        "        else:\n",
        "            self.root = Node(None)\n",
        "\n",
        "    def __del__(self):\n",
        "        del self.root\n",
        "\n",
        "    def create_tree(self, records_df, attributes=None):\n",
        "        \"\"\"creates the tree and returns the root\"\"\"\n",
        "        if not attributes:\n",
        "            attributes = list(records_df.columns)\n",
        "            attributes.remove(self.goal)\n",
        "        return self.recursive_build(records_df, attributes, [], 0)\n",
        "\n",
        "    def recursive_build(self, records_df, attributes, path, depth):\n",
        "        \"\"\"Recursive helper to build the tree\"\"\"\n",
        "        if self.limit and self.limit <= depth:\n",
        "            attribute = None\n",
        "        else:\n",
        "            attribute = self.get_next_attribute(attributes, records_df)\n",
        "            while attribute and len(records_df[attribute].value_counts()) == 1:\n",
        "                attributes.remove(attribute)\n",
        "                attribute = self.get_next_attribute(attributes, records_df)\n",
        "        if not attribute:\n",
        "            attribute = self.goal\n",
        "        if attribute != self.goal:\n",
        "            attributes.remove(attribute)\n",
        "            if not path:\n",
        "                node = Node(attribute, depth=depth)\n",
        "            else:\n",
        "                node = Node(attribute, path, depth)\n",
        "            children = []\n",
        "            for val in records_df[attribute].unique():\n",
        "                new_data = records_df[records_df[attribute] == val]\n",
        "                new_path = copy.deepcopy(path + [(attribute, val)])\n",
        "                records_df = records_df[records_df[attribute] != val]\n",
        "                remaining = copy.deepcopy(attributes)\n",
        "                children.append(self.recursive_build(new_data, remaining,\n",
        "                                                     new_path, depth + 1))\n",
        "            node.add_children(children)\n",
        "        else:\n",
        "            node = Node(self.decide_leaf(records_df), path, depth=depth)\n",
        "        return node\n",
        "\n",
        "    def get_next_attribute(self, attribute_list, records_df):\n",
        "        \"\"\"returns the next attribute\"\"\"\n",
        "        if attribute_list:\n",
        "            return attribute_list[0]\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def decide_leaf(self, records_df):\n",
        "        \"\"\"Decide the value of the leaf based on the records\"\"\"\n",
        "        if records_df.empty:\n",
        "            return None\n",
        "        return records_df[self.goal].value_counts().argmax()\n",
        "\n",
        "    def pruning(self, records_df, threshold):\n",
        "        \"\"\"Prunes the tree based on a threshold\"\"\"\n",
        "        nodes_to_check = [self.root]\n",
        "        while nodes_to_check:\n",
        "            node = nodes_to_check.pop()\n",
        "            children_remove = []\n",
        "            children_append = []\n",
        "            for child in node.children:\n",
        "                path = child.choices\n",
        "                depth = child.depth\n",
        "                relevant = copy.deepcopy(records_df)\n",
        "                for attribute, value in path:\n",
        "                    relevant = relevant[relevant[attribute] == value]\n",
        "                if len(relevant) / self.rows <= threshold:\n",
        "                    children_remove.append(child)\n",
        "                    children_append.append(Node(self.decide_leaf(relevant),\n",
        "                                              path, depth=depth))\n",
        "                else:\n",
        "                    nodes_to_check.append(child)\n",
        "            for child in children_remove:\n",
        "                node.children.remove(child)\n",
        "            for child in children_append:\n",
        "                node.children.append(child)\n",
        "\n",
        "    def get_val(self, df_row):\n",
        "        \"\"\"Gets the relevant node based on the row\"\"\"\n",
        "        node = self.root\n",
        "        while node:\n",
        "            prev_node = node\n",
        "            if not len(node.children):\n",
        "                return node.data\n",
        "            if node.data not in df_row.keys():\n",
        "                return None\n",
        "            children = prev_node.children\n",
        "            for child in children:\n",
        "                if child.choices[-1][1] == df_row[prev_node.data]:\n",
        "                    node = child\n",
        "                    break\n",
        "                else:\n",
        "                    node = None\n",
        "        return None\n",
        "\n",
        "    def save_tree(self, output_path):\n",
        "        \"\"\"Saves the tree\"\"\"\n",
        "        with open(output_path, 'wb') as file:\n",
        "            pickle.dump(self, file)\n",
        "\n",
        "    def load_tree(self, path):\n",
        "        \"\"\"Saves the tree\"\"\"\n",
        "        with open(path, 'rb') as file:\n",
        "            node = pickle.load(file)\n",
        "        self.root = node.root\n",
        "\n",
        "\n",
        "class EntropyTree(Tree):\n",
        "    def get_next_attribute(self, attribute_list, records_df):\n",
        "        \"\"\"returns the attribute with the minimum entropy\"\"\"\n",
        "        entropy = calc_entropy(attribute_list, records_df)\n",
        "        entropy = {k: v for k, v in entropy.items() if v}\n",
        "        if len(entropy):\n",
        "            return min(entropy, key=entropy.get)\n",
        "        return None\n",
        "\n",
        "\n",
        "class InformationGainTree(Tree):\n",
        "    def get_next_attribute(self, attribute_list, records_df):\n",
        "        \"\"\"Returns the attribute with the highest information gain\"\"\"\n",
        "        info_gain = information_gain(attribute_list, records_df)\n",
        "        if len(info_gain):\n",
        "            return max(info_gain, key=info_gain.get)\n",
        "        return None\n",
        "\n",
        "\n",
        "class InformationRatioTree(Tree):\n",
        "    def get_next_attribute(self, attribute_list, records_df):\n",
        "        \"\"\"Returns the attribute with the highest information gain ratio\"\"\"\n",
        "        info_gain = information_gain(attribute_list, records_df)\n",
        "        info_gain_ratio = dict()\n",
        "        for attribute in attribute_list:\n",
        "            p = records_df[attribute].value_counts() / len(records_df)\n",
        "            int_value = -np.sum(p * np.log2(p))\n",
        "            info_gain_ratio[attribute] = info_gain[attribute] / int_value\n",
        "        if len(info_gain_ratio):\n",
        "            return max(info_gain_ratio, key=info_gain_ratio.get)\n",
        "        return None\n",
        "\n",
        "\n",
        "def calc_entropy(attribute_list, records_df):\n",
        "    \"\"\"Returns the entropy dictionary\"\"\"\n",
        "    entropy = dict()\n",
        "    for attribute in attribute_list:\n",
        "        p = records_df[attribute].value_counts() / len(records_df)\n",
        "        entropy[attribute] = -np.sum(p * np.log2(p))\n",
        "    return entropy\n",
        "\n",
        "\n",
        "def information_gain(attribute_list, records_df, goal=GOAL):\n",
        "    \"\"\"Returns a dictionary of the information gain\"\"\"\n",
        "    goal_entropy = calc_entropy([goal], records_df)[goal]\n",
        "    info_gain = dict()\n",
        "    for attribute in attribute_list:\n",
        "        remaining_entropy = 0\n",
        "        for val in records_df[attribute].unique():\n",
        "            relevant = records_df[records_df[attribute] == val]\n",
        "            p = relevant[goal].value_counts() / len(relevant)\n",
        "            remaining_entropy += -(np.sum(p * np.log2(p) * len(relevant)) / len(records_df))\n",
        "        info_gain[attribute] = goal_entropy - remaining_entropy\n",
        "    return info_gain\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q3irnrraQXX",
        "colab_type": "text"
      },
      "source": [
        "##Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPXFTT18fDwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "from multiprocessing import Pool"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsxzgQDFaGtQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH_TO_FOLDER = \"/content/gdrive/My Drive/AI_project/\"\n",
        "INPUT_PATH = \"Data/training_data_1.csv\"\n",
        "GOAL = \"demand\"\n",
        "TRAIN_LEVEL = 0.5\n",
        "POOL_SIZE = 4\n",
        "TREE = \"tree\"\n",
        "ENTROPY = \"entropy\"\n",
        "INFORMATION_GAIN = \"information_gain\"\n",
        "INFORMATION_RATIO = \"information_ratio\"\n",
        "BASIC_ATTRIBUTES = [\"L1\", \"L2\", \"time\"]\n",
        "IGNORE_LIST = BASIC_ATTRIBUTES + [\"Unnamed: 0\", \"Unnamed: 0.1\", \"cluster_id\",\n",
        "                                  \"thunderstorm\", \"foggy\", \"humidity\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B9HuLlOaWs_",
        "colab_type": "text"
      },
      "source": [
        "##Function defenitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csxjot8taXFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tree_creation(type, records_df, limit=0, attributes=None, goal=GOAL):\n",
        "    \"\"\"This function creates the trees\"\"\"\n",
        "    if type == TREE:\n",
        "        return Tree(records_df, limit, attributes, goal)\n",
        "    elif type == ENTROPY:\n",
        "        return EntropyTree(records_df, limit, attributes, goal)\n",
        "    elif type == INFORMATION_GAIN:\n",
        "        return InformationGainTree(records_df, limit, attributes, goal)\n",
        "    elif type == INFORMATION_RATIO:\n",
        "        return InformationRatioTree(records_df, limit, attributes, goal)\n",
        "    else:\n",
        "        return\n",
        "\n",
        "\n",
        "def create_attributes_list(data):\n",
        "    \"\"\"Creates a list of attributes in order to build th trees\"\"\"\n",
        "    attributes_list = []\n",
        "    for column in data.columns:\n",
        "        if column not in IGNORE_LIST:\n",
        "            attributes_list.append(BASIC_ATTRIBUTES + [column])\n",
        "    return attributes_list\n",
        "\n",
        "\n",
        "def get_type(tree):\n",
        "    \"\"\"Gets the type of the tree\"\"\"\n",
        "    return str(type(tree)).split('.')[1].split('\\'')[0]\n",
        "\n",
        "\n",
        "def create_trees(training_data, goal):\n",
        "    \"\"\"This function creates the trees using multi-threading\"\"\"\n",
        "    p = Pool(POOL_SIZE)\n",
        "    # every tree we want to create has to come in the format of\n",
        "    # (type, df, limit, attributes, goal)\n",
        "    attr_list = create_attributes_list(training_data)\n",
        "    for lst in attr_list:\n",
        "        print(lst[-1])\n",
        "        res = []\n",
        "        trees = []\n",
        "        trees = [(TREE, training_data, 0, lst, goal)]\n",
        "        trees.append((ENTROPY, training_data, 0, lst, goal))\n",
        "        trees.append((INFORMATION_GAIN, training_data, 0, lst, goal))\n",
        "        trees.append((INFORMATION_RATIO, training_data, 0, lst, goal))\n",
        "        res = p.starmap(tree_creation, trees)\n",
        "        for t in res:\n",
        "            t.save_tree(PATH_TO_FOLDER + \"Trees/\" + get_type(t) + \"_\" + lst[-1] \n",
        "                        + \"_1.txt\")\n",
        "    p.close()\n",
        "    p.join()\n",
        "\n",
        "\n",
        "def create_file(test_data, all_trees, goal):\n",
        "    \"\"\"This function generates a file with the results of each tree and the\n",
        "    actual result per line in the test data\"\"\"\n",
        "    columns = [\"tree\" + str(i) for i in range(len(all_trees))]\n",
        "    columns.append(goal)\n",
        "    output = pd.DataFrame(columns=columns)\n",
        "    for i in range(len(test_data)):\n",
        "        row_dict = dict()\n",
        "        row = test_data.iloc[i, :]\n",
        "        for t in all_trees:\n",
        "            row_dict[\"tree\" + str(all_trees.index(t))] = t.get_val(row)\n",
        "        row_dict[goal] = row[goal]\n",
        "        output = output.append(pd.DataFrame.from_dict([row_dict]))\n",
        "    output.to_csv(PATH_TO_FOLDER + \"Data/testing_by_tree.csv\")\n",
        "\n",
        "\n",
        "def export_trees(all_trees):\n",
        "    \"\"\"This function saves all the trees to files\"\"\"\n",
        "    for t in all_trees:\n",
        "        t.save_tree(\"trees/tree\" + str(all_trees.index(t)) + \".txt\")\n",
        "\n",
        "\n",
        "def export_training_and_test(training_data, test_data):\n",
        "    \"\"\"This functino saves the training data and the testing data\"\"\"\n",
        "    training_data.to_csv(\"training_data.csv\")\n",
        "    test_data.to_csv(\"test_data.csv\")\n",
        "    \n",
        "def load_data(path):\n",
        "    \"\"\"\"\"\"\n",
        "    return pd.read_csv(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUJxExWnKpVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCH1bYYHagvA",
        "colab_type": "text"
      },
      "source": [
        "##Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBtorAPyaSf3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "outputId": "2fcb47d7-0866-46da-8d1c-33a0c50f0549"
      },
      "source": [
        "    training_data = pd.read_csv(PATH_TO_FOLDER + INPUT_PATH)\n",
        "    # create trees based on training data\n",
        "    create_trees(training_data, GOAL)\n",
        "    # export_trees(all_trees)\n",
        "\n",
        "    # create file\n",
        "    # create_file(test_data, all_trees, GOAL)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weekday\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:91: FutureWarning: \n",
            "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
            "instead.\n",
            "The behavior of 'argmax' will be corrected to return the positional\n",
            "maximum in the future. For now, use 'series.values.argmax' or\n",
            "'np.argmax(np.array(values))' to get the position of the maximum\n",
            "row.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:91: FutureWarning: \n",
            "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
            "instead.\n",
            "The behavior of 'argmax' will be corrected to return the positional\n",
            "maximum in the future. For now, use 'series.values.argmax' or\n",
            "'np.argmax(np.array(values))' to get the position of the maximum\n",
            "row.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:174: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:91: FutureWarning: \n",
            "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
            "instead.\n",
            "The behavior of 'argmax' will be corrected to return the positional\n",
            "maximum in the future. For now, use 'series.values.argmax' or\n",
            "'np.argmax(np.array(values))' to get the position of the maximum\n",
            "row.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:91: FutureWarning: \n",
            "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
            "instead.\n",
            "The behavior of 'argmax' will be corrected to return the positional\n",
            "maximum in the future. For now, use 'series.values.argmax' or\n",
            "'np.argmax(np.array(values))' to get the position of the maximum\n",
            "row.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:174: RuntimeWarning: invalid value encountered in double_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "holiday\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:174: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:174: RuntimeWarning: invalid value encountered in double_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "month\n",
            "clear_sky\n",
            "extreme_weather\n",
            "rain\n",
            "temperature\n",
            "wind\n",
            "wintry\n",
            "demand\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54jjRfNAmIzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(PATH_TO_FOLDER + INPUT_PATH)\n",
        "attributes = BASIC_ATTRIBUTES + [\"clear_sky\"]\n",
        "entropy = EntropyTree(data, 0, attributes, GOAL)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}