{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kfir1g/AI-Project/blob/master/ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiq3LhGCRiCS",
        "colab_type": "code",
        "outputId": "84b29341-22bd-4bd1-baa9-f12fbc99d2ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDcd_iqX3T-5",
        "colab_type": "text"
      },
      "source": [
        "#Initialize tensorflow-GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsOM9HBM2nSc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "outputId": "b6f4bc05-a293-4cf7-9f75-3264c7945afd"
      },
      "source": [
        "!pip install tensorflow-gpu\n",
        "import tensorflow as tf \n",
        "#test111"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/04/43153bfdfcf6c9a4c38ecdb971ca9a75b9a791bb69a764d652c359aca504/tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0MB)\n",
            "\u001b[K     |████████████████████████████████| 377.0MB 51kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.1.7)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.16.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.7.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.14.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu) (41.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu) (3.1.1)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoUX67u4AMfV",
        "colab_type": "text"
      },
      "source": [
        "##This part makes sure that we are working on GPU in runtime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2q4JizSKFbC",
        "colab_type": "code",
        "outputId": "bba098ad-a9a3-45d0-f47f-83818ff27fd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at : {}'.format(device_name))  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at : /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M83BQ3l232h",
        "colab_type": "text"
      },
      "source": [
        "#Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2EglwEr6ptD",
        "colab_type": "text"
      },
      "source": [
        "##importing Libraries and Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8eAaNYAAXlu",
        "colab_type": "text"
      },
      "source": [
        "##Import the data\n",
        "data is the results of each tree on each line of the testing data + the actual value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptPIzXyE1WDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import files\n",
        "#file = files.upload()\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "filename = #path of the file to be trained\n",
        "dataset = pd.read_csv(\"/content/gdrive/\" + filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upBJoMgW69Ra",
        "colab_type": "text"
      },
      "source": [
        "##Getting the dependent and independent variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYxgxwUHAw72",
        "colab_type": "text"
      },
      "source": [
        "splits the information to results from tree and actual result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NF8DEI1s3IoS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = dataset.iloc[:,1:-1].values \n",
        "y = dataset.iloc[:,-1].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXz_mmclA9WM",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toOqSp2fFyNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_PICKUP_BIKES = y.max() +1 #Todo: check what is the max number\n",
        "NUM_OF_INPUTS = X.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yds98lZrCpWJ",
        "colab_type": "text"
      },
      "source": [
        "##Splitting the dataset into training set and Test set "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfFytAK4A_yy",
        "colab_type": "text"
      },
      "source": [
        "Splits the information to training and test for the NN, test_size can be changed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCdgLLE6Dm8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size = 0.2, random_state = 0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zLnOPZzFBSP",
        "colab_type": "text"
      },
      "source": [
        "##Feature scaling - not needed for trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY_oW3QXCyz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Not needed for sure\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "sc_Y = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl9CxwwdGnqE",
        "colab_type": "text"
      },
      "source": [
        "#Builed the NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE-esM_NCGJ4",
        "colab_type": "text"
      },
      "source": [
        "##Parameters for NN\n",
        "softmax - output neuron that got the highest value\n",
        "Epoch - how many time will go over all the data\n",
        "Batch_size - update weights every batch inputs\n",
        "Can add more layers or change the numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZPOMzTwIVP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FIRST_LAYAR = 200\n",
        "SECONED_LAYAR = 200\n",
        "OUTPUT_ACTIVATION_FUNC = 'softmax'\n",
        "OPTIMIZER = 'adam' #'rmsprop' #stochastich gradient descent\n",
        "NUM_EPOCH = 100\n",
        "BATCH_SIZE = 75"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "162SXMnADiCW",
        "colab_type": "text"
      },
      "source": [
        "First layer has to have num_of_inputs\n",
        "Last layer has to have that activation\n",
        "We can add more layers, by copying the add option and changing options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LkNjZ60E_-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "classifier = Sequential()\n",
        "\n",
        "classifier.add(Dense(output_dim = FIRST_LAYAR  , init = 'uniform', activation = 'relu', input_dim = NUM_OF_INPUTS))\n",
        "classifier.add(Dense(output_dim = SECONED_LAYAR, init = 'uniform', activation = 'relu' ))\n",
        "classifier.add(Dense(output_dim =MAX_PICKUP_BIKES, init = 'uniform', activation = OUTPUT_ACTIVATION_FUNC ))\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aOw3-a4GhoW",
        "colab_type": "text"
      },
      "source": [
        "#Define Optimizer and Loss function "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AXnwRlgEMAW",
        "colab_type": "text"
      },
      "source": [
        "Change the values to change the NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnERn7meGWV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.compile(optimizer = OPTIMIZER , loss = 'sparse_categorical_crossentropy',metrics = ['accuracy']) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1rz83HWGtIM",
        "colab_type": "text"
      },
      "source": [
        "#Train the data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWfDQcyqEbwe",
        "colab_type": "text"
      },
      "source": [
        "fit is the training, after that saves the weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnZxcKkgG0iE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.fit(X_train, Y_train, batch_size = BATCH_SIZE , nb_epoch = NUM_EPOCH)\n",
        "from keras.models import load_model\n",
        "classifier.save_weights('/content/gdrive/My Drive/AIProj/my_model_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLNRka6un5Be",
        "colab_type": "text"
      },
      "source": [
        "#Extract the predctions \n",
        "\n",
        "\n",
        "1.   getting the predection from the classifier\n",
        "2.   extracting the argmax which is the number of picups fo reach input\n",
        "3.  checking while using the test vector our results\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coVsoZZVHm22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_pred = classifier.predict(X_test)\n",
        "Y_get = []\n",
        "for i in range(len(Y_pred)):\n",
        "  Y_get.append(Y_pred[i].argmax())\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMdBpKxzITYF",
        "colab_type": "code",
        "outputId": "cd4ced98-7dfd-4ee2-a684-452ea72b6a0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "total = 0 \n",
        "correct = 0 \n",
        "wrong = 0 \n",
        "for i in range(len(Y_pred)):\n",
        "  total = total +1\n",
        "  if(Y_get[i] == Y_test[i]):\n",
        "     correct = correct + 1\n",
        "  else:\n",
        "    wrong = wrong + 1\n",
        "    \n",
        "print(\"Total \"+ str(total) )\n",
        "print(\"Correct \" + str(correct))\n",
        "print(\"Wrong \" + str(wrong))\n",
        "print(\"acc:\" + str(float(correct)/total) )\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total 30138\n",
            "Correct 9819\n",
            "Wrong 20319\n",
            "acc:0.3258013139558033\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcKwA-p8FFbj",
        "colab_type": "text"
      },
      "source": [
        "#Load Wights \n",
        "To Load wights you need to create the model again and use the classifier to predict  - need to be tested"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcQ_SYsfFBHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "MAX_PICKUP_BIKES = y.max() +1 #Todo: check what is the max number\n",
        "NUM_OF_INPUTS = X.shape[1]\n",
        "FIRST_LAYAR = 200\n",
        "SECONED_LAYAR = 200\n",
        "OUTPUT_ACTIVATION_FUNC = 'softmax'\n",
        "OPTIMIZER = 'rmsprop' #'adam' #stochastich gradient descent\n",
        "NUM_EPOCH = 100\n",
        "BATCH_SIZE = 75\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "classifier = Sequential()\n",
        "\n",
        "classifier.add(Dense(output_dim = FIRST_LAYAR  , init = 'uniform',activation ='relu',input_dim = NUM_OF_INPUTS ))\n",
        "classifier.add(Dense(output_dim = SECONED_LAYAR, init = 'uniform', activation = 'relu' ))\n",
        "classifier.add(Dense(output_dim =355, init = 'uniform', activation = OUTPUT_ACTIVATION_FUNC ))\n",
        "classifier.load_weights('my_model_weights.h5')\n",
        "\n",
        "#How to predict one input: \n",
        "\n",
        "input_vector = #put input vector you want to test\n",
        "Y_pred = classifier.predict(input_vector)\n",
        "pickup_predection = Y_pred[0].argmax()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubcrHwhcdPiv",
        "colab_type": "text"
      },
      "source": [
        "#Evaluating the ANN "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpYGtDaCeBxr",
        "colab_type": "text"
      },
      "source": [
        "##Using K-Fold Cross Validation \n",
        "The main idea is dividing to 10 folds and taking the mean and variance, the mean is the actual result of our ANN and the variance will indicate if we are overfitting\n",
        "NN needs to be the same as before"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1v8GVajdO8E",
        "colab_type": "code",
        "outputId": "2b19c04a-637b-479c-e468-8fcc00e80cc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "def build_classifier():\n",
        "  classifier = Sequential()\n",
        "\n",
        "  classifier.add(Dense(output_dim = FIRST_LAYAR  , init = 'uniform',activation ='relu',input_dim = NUM_OF_INPUTS ))\n",
        "  classifier.add(Dense(output_dim = SECONED_LAYAR, init = 'uniform', activation = 'relu' ))\n",
        "  classifier.add(Dense(output_dim = 355, init = 'uniform', activation = OUTPUT_ACTIVATION_FUNC ))\n",
        "  classifier.compile(optimizer = 'adam'  , loss = 'sparse_categorical_crossentropy',metrics = ['accuracy'])\n",
        "  return classifier\n",
        "\n",
        "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 75, nb_epoch = 250 )\n",
        "accuracies = cross_val_score(estimator = classifier, X = X_train, y = Y_train, cv =10, n_jobs = -1)# cv num of folds , n_jobs =-1 usingall the GPU\n",
        "#Accuracies is a vector with all the #folds results(in our case 10) \n",
        "#The real Result is the mean of this vector, also we need to check for hight or low variance to know if our results are good\n",
        "mean = accuracies.mean()\n",
        "variance = accuracies.std()\n",
        "variance\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.005668231143304357"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4_ul6loKRfg",
        "colab_type": "code",
        "outputId": "e064b449-b9e0-43d7-f536-3cc872ce8e57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mean"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.32813215512885086"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hef3LqejkP-S",
        "colab_type": "text"
      },
      "source": [
        "#Improving the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO-KrJGSkkip",
        "colab_type": "text"
      },
      "source": [
        "##Droput Regularization to reduce overfitting if needed \n",
        "While Getting big variance, meaning the model was doing well on some and than really bad on others, so he is overfitting on the training.\n",
        "This startagy will help fixing it. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YA3ynqBQl94C",
        "colab_type": "text"
      },
      "source": [
        "##Tuning The ANN - choose the best param from all the options\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KzTSvH7l_-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "def build_classifier(optimizer,first, seconed ):\n",
        "  classifier = Sequential()\n",
        "\n",
        "  classifier.add(Dense(output_dim = first  , init = 'uniform',activation ='relu',input_dim = NUM_OF_INPUTS ))\n",
        "  classifier.add(Dense(output_dim = seconed, init = 'uniform', activation = 'relu' ))\n",
        "  classifier.add(Dense(output_dim = 355, init = 'uniform', activation = OUTPUT_ACTIVATION_FUNC ))\n",
        "  classifier.compile(optimizer = optimizer  , loss = 'sparse_categorical_crossentropy',metrics = ['accuracy'])\n",
        "  return classifier\n",
        "\n",
        "classifier = KerasClassifier(build_fn = build_classifier)\n",
        "parameters = {'batch_size': [25, 32 ],'nb_epochs': [250, 500], 'optimizer' : ['adam', 'rmsprop'], 'first': [100,200], 'seconed':[100,200]}\n",
        "grid_search = GridSearchCV(estimator = classifier, param_grid = parameters, scoring = 'accuracy', cv = 10)  \n",
        "grid_serach = grid_search.fit(X_train, Y_train)                     \n",
        "best_parameters = grid_serach.best_params_\n",
        "best_accuracy = grid_search.best_score_"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}