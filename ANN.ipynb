{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDcd_iqX3T-5",
        "colab_type": "text"
      },
      "source": [
        "#Initialize tensorflow-GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiq3LhGCRiCS",
        "colab_type": "code",
        "outputId": "966a56a8-9e41-48d7-85b6-4a7ba5c17429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsOM9HBM2nSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu\n",
        "import tensorflow as tf \n",
        "#test111"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2q4JizSKFbC",
        "colab_type": "code",
        "outputId": "bba098ad-a9a3-45d0-f47f-83818ff27fd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at : {}'.format(device_name))  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at : /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M83BQ3l232h",
        "colab_type": "text"
      },
      "source": [
        "#Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2EglwEr6ptD",
        "colab_type": "text"
      },
      "source": [
        "##importing Libraries and Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptPIzXyE1WDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import files\n",
        "#file = files.upload()\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "dataset = pd.read_csv(\"/content/gdrive/My Drive/AIProj/pickups_2019.csv\")\n",
        "dataset = dataset.drop(['cluster_id'], axis = 1)             \n",
        "dataset.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTrJUyIAsR8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv(\"/content/gdrive/My Drive/AIProj/pickups_2019.csv\")\n",
        "dataset['weekday']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upBJoMgW69Ra",
        "colab_type": "text"
      },
      "source": [
        "##Getting the dependent and independent variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IC83s5U-yBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ToMinutes(t):\n",
        "  (h, m, s) = t.split(':')\n",
        "  result = float(h) *60+ float(m) + float(s)/60\n",
        "  return str(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NF8DEI1s3IoS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "timeCol = dataset['time']\n",
        "dataset['time'] = timeCol.apply((lambda x: ToMinutes(x)))\n",
        "X = dataset.iloc[:,1:-1].values \n",
        "y = dataset['pickups'].values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toOqSp2fFyNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_PICKUP_BIKES = y.max() +1\n",
        "NUM_OF_INPUTS = X.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yds98lZrCpWJ",
        "colab_type": "text"
      },
      "source": [
        "##Splitting the dataset into training set and Test set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCdgLLE6Dm8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size = 0.2, random_state = 0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zLnOPZzFBSP",
        "colab_type": "text"
      },
      "source": [
        "##Feature scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY_oW3QXCyz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "sc_Y = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZPOMzTwIVP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FIRST_LAYAR = 200\n",
        "SECONED_LAYAR = 200\n",
        "OUTPUT_ACTIVATION_FUNC = 'softmax'\n",
        "OPTIMIZER = 'rmsprop' #'adam' #stochastich gradient descent\n",
        "NUM_EPOCH = 100\n",
        "BATCH_SIZE = 75"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl9CxwwdGnqE",
        "colab_type": "text"
      },
      "source": [
        "#Builed the NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LkNjZ60E_-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "classifier = Sequential()\n",
        "\n",
        "classifier.add(Dense(output_dim = FIRST_LAYAR  , init = 'uniform',activation ='relu',input_dim = NUM_OF_INPUTS ))\n",
        "classifier.add(Dense(output_dim = SECONED_LAYAR, init = 'uniform', activation = 'relu' ))\n",
        "classifier.add(Dense(output_dim =355, init = 'uniform', activation = OUTPUT_ACTIVATION_FUNC ))\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aOw3-a4GhoW",
        "colab_type": "text"
      },
      "source": [
        "#Define Optimizer and Loss function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnERn7meGWV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.compile(optimizer = OPTIMIZER , loss = 'sparse_categorical_crossentropy',metrics = ['accuracy']) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_WXCm1q7Ou3",
        "colab_type": "text"
      },
      "source": [
        "Set Values: \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1rz83HWGtIM",
        "colab_type": "text"
      },
      "source": [
        "#Train the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnZxcKkgG0iE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.fit(X_train, Y_train, batch_size = BATCH_SIZE , nb_epoch = NUM_EPOCH)\n",
        "from keras.models import load_model\n",
        "classifier.save_weights('/content/gdrive/My Drive/AIProj/my_model_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjjpNVO7ghMb",
        "colab_type": "text"
      },
      "source": [
        "#Results TODO: Check how to save wights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coVsoZZVHm22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_pred = classifier.predict(X_test)\n",
        "Y_get = []\n",
        "for i in range(len(Y_pred)):\n",
        "  Y_get.append(Y_pred[i].argmax())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMdBpKxzITYF",
        "colab_type": "code",
        "outputId": "cd4ced98-7dfd-4ee2-a684-452ea72b6a0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "total = 0 \n",
        "correct = 0 \n",
        "wrong = 0 \n",
        "for i in range(len(Y_pred)):\n",
        "  total = total +1\n",
        "  if(Y_get[i] == Y_test[i]):\n",
        "     correct = correct + 1\n",
        "  else:\n",
        "    wrong = wrong + 1\n",
        "    \n",
        "print(\"Total \"+ str(total) )\n",
        "print(\"Correct \" + str(correct))\n",
        "print(\"Wrong \" + str(wrong))\n",
        "print(\"acc:\" + str(float(correct)/total) )\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total 30138\n",
            "Correct 9819\n",
            "Wrong 20319\n",
            "acc:0.3258013139558033\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfsra6HgE8bq",
        "colab_type": "text"
      },
      "source": [
        "#Save wights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxYDCYK6EsnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "classifier.save_weights('my_model_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcKwA-p8FFbj",
        "colab_type": "text"
      },
      "source": [
        "#Load Wights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcQ_SYsfFBHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.load_weights('my_model_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubcrHwhcdPiv",
        "colab_type": "text"
      },
      "source": [
        "#Evaluating the ANN "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpYGtDaCeBxr",
        "colab_type": "text"
      },
      "source": [
        "#Using K-Fold Cross Validation \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1v8GVajdO8E",
        "colab_type": "code",
        "outputId": "2b19c04a-637b-479c-e468-8fcc00e80cc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "def build_classifier():\n",
        "  classifier = Sequential()\n",
        "\n",
        "  classifier.add(Dense(output_dim = FIRST_LAYAR  , init = 'uniform',activation ='relu',input_dim = NUM_OF_INPUTS ))\n",
        "  classifier.add(Dense(output_dim = SECONED_LAYAR, init = 'uniform', activation = 'relu' ))\n",
        "  classifier.add(Dense(output_dim = 355, init = 'uniform', activation = OUTPUT_ACTIVATION_FUNC ))\n",
        "  classifier.compile(optimizer = 'adam'  , loss = 'sparse_categorical_crossentropy',metrics = ['accuracy'])\n",
        "  return classifier\n",
        "\n",
        "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 75, nb_epoch = 250 )\n",
        "accuracies = cross_val_score(estimator = classifier, X = X_train, y = Y_train, cv =10, n_jobs = -1)# cv num of folds , n_jobs =-1 usingall the GPU\n",
        "#Accuracies is a vector with all the #folds results(in our case 10) \n",
        "#The real Result is the mean of this vector, also we need to check for hight or low variance to know if our results are good\n",
        "mean = accuracies.mean()\n",
        "variance = accuracies.std()\n",
        "mean \n",
        "variance\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.005668231143304357"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4_ul6loKRfg",
        "colab_type": "code",
        "outputId": "e064b449-b9e0-43d7-f536-3cc872ce8e57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mean"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.32813215512885086"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hef3LqejkP-S",
        "colab_type": "text"
      },
      "source": [
        "#Improving the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO-KrJGSkkip",
        "colab_type": "text"
      },
      "source": [
        "#Droput Regularization to reduce overfitting if needed \n",
        "While Getting big variance, meaning the model was doing well on some and than really bad on others, so he is overfitting on the training.\n",
        "This startagy will help fixing it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2LzC526g5Mu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iDvS4f_lkpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YA3ynqBQl94C",
        "colab_type": "text"
      },
      "source": [
        "#Tuning The ANN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KzTSvH7l_-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "def build_classifier(optimizer,first, seconed ):\n",
        "  classifier = Sequential()\n",
        "\n",
        "  classifier.add(Dense(output_dim = first  , init = 'uniform',activation ='relu',input_dim = NUM_OF_INPUTS ))\n",
        "  classifier.add(Dense(output_dim = seconed, init = 'uniform', activation = 'relu' ))\n",
        "  classifier.add(Dense(output_dim = 355, init = 'uniform', activation = OUTPUT_ACTIVATION_FUNC ))\n",
        "  classifier.compile(optimizer = optimizer  , loss = 'sparse_categorical_crossentropy',metrics = ['accuracy'])\n",
        "  return classifier\n",
        "\n",
        "classifier = KerasClassifier(build_fn = build_classifier)\n",
        "parameters = {'batch_size': [25, 32 ],'nb_epochs': [250, 500], 'optimizer' : ['adam', 'rmsprop'], 'first': [100,200], 'seconed':[100,200]}\n",
        "grid_search = GridSearchCV(estimator = classifier, param_grid = parameters, scoring = 'accuracy', cv = 10)  \n",
        "grid_serach = grid_search.fit(X_train, Y_train)                     \n",
        "best_parameters = grid_serach.best_params_\n",
        "best_accuracy = grid_search.best_score_"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}